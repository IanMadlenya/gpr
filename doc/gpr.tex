\documentclass[12pt]{article}

\usepackage[usenames]{color}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{accents}

\DeclareMathAlphabet{\mathsfsl}{OT1}{cmss}{m}{sl}

\newcommand{\red}{\textcolor{red}}
\newcommand{\blue}{\textcolor{blue}}

\newcommand{\dif}{\mathrm{d}}

\newcommand{\myu}[1]{\underaccent{\bar}{#1}}

\newcommand{\onehalf}{\tfrac{1}{2}}

\newcommand{\mat}[1]{\mbox{$\mathsfsl{#1}$}}
\newcommand{\myvec}[1]{\mbox{\boldmath$#1$}}

\newcommand{\diagv}[1]{\mathrm{diag_v}(#1)}
\newcommand{\diagm}[1]{\mathrm{diag_m}(#1)}
\newcommand{\trace}[1]{\mathrm{tr}(#1)}
\newcommand{\transv}[1]{\myvec{#1}^\top}
\newcommand{\transm}[1]{\mat{#1}^\top}

\newcommand{\imat}[1]{\mat{#1^{-1}}}
\newcommand{\ichol}[1]{\mat{#1^{-\onehalf}}}
\newcommand{\icholt}[1]{\mat{#1^{-\tfrac{\top}{2}}}}

\newcommand{\Km}{\mat{K_M}}
\newcommand{\iKm}{\imat{K_M}}
\newcommand{\dKm}{\mat{\dot{K}_M}}
\newcommand{\dKn}{\mat{\dot{K}_N}}
\newcommand{\Kmn}{\mat{K_{MN}}}
\newcommand{\Knm}{\transm{K_{MN}}}
\newcommand{\uKnm}{\myu{\mat{K}}_{\mathsfsl{MN}}^\top}
\newcommand{\uuKnm}{\myu{\myu{\mat{K}}}_{\mathsfsl{MN}}^\top}
\newcommand{\dKmn}{\mat{\dot{K}_{MN}}}
\newcommand{\uKmn}{\myu{\mat{K}}_{\mathsfsl{MN}}}
\newcommand{\uuKmn}{\myu{\myu{\mat{K}}}_{\mathsfsl{MN}}}

\newcommand{\dl}{\dot{l}}

\newcommand{\vece}{\myvec{e}}
\newcommand{\vecr}{\myvec{r}}
\newcommand{\vecs}{\myvec{s}}
\newcommand{\vect}{\myvec{t}}
\newcommand{\vecu}{\myvec{u}}
\newcommand{\vecv}{\myvec{v}}
\newcommand{\vecvc}{\myvec{v}_c}
\newcommand{\vecvx}{\myvec{v}_1}
\newcommand{\vecvy}{\myvec{v}_2}
\newcommand{\vecy}{\myvec{y}}
\newcommand{\uuvecy}{\myu{\myu{\vecy}}}

\newcommand{\vecsdh}{\onehalf\myvec{\dot{s}}}
\newcommand{\vecis}{\myvec{s}^{-1}}
\newcommand{\veciss}{\myvec{s}^{-\onehalf}}

\newcommand{\matB}{\mat{B}}
\newcommand{\matI}{\mat{I}}
\newcommand{\matR}{\mat{R}}
\newcommand{\matS}{\mat{S}}
\newcommand{\matT}{\mat{T}}
\newcommand{\matU}{\mat{U}}
\newcommand{\matUx}{\mat{U}_1}
\newcommand{\matUy}{\mat{U}_2}
\newcommand{\matV}{\mat{V}}
\newcommand{\matW}{\mat{W}}
\newcommand{\matWx}{\mat{W}_1}
\newcommand{\matX}{\mat{X}}
\newcommand{\matXx}{\mat{X}_1}
\newcommand{\matWy}{\mat{W}_2}
\newcommand{\matXy}{\mat{X}_2}

\newcommand{\Lam}{\mat{\Lambda}}
\newcommand{\Lamss}{\mat{\Lambda}_{\sigma^2}}
\newcommand{\Lamssi}{\imat{\Lambda_{\sigma^2}}}

\begin{document}

\section{FIC computations}

These are the equations used for computing the FIC predictive
distribution and FIC marginal likelihood and its derivatives in the
OCaml-implementation.  The implementation factorizes the computations
in that way to minimize computation time (primarily) and memory
usage.  It also takes into account numerical stability (e.g.\
avoiding inverses) whenever possible without great loss of efficiency
and otherwise aims for ease of implementation, e.g.\ combining
derivative terms to simplify dealing with sparse matrices.\\

Here are a few symbology conventions:

\begin{itemize}
\item $\mathrm{diag_m}$ is the matrix consisting of only the diagonal
\item Parts in \red{red} represent terms used for Michalis Titsias'
variational approximation of the posterior marginal likelihood.
\item Parts in \blue{blue} give an alternative, more compact, direct
and hence more efficient way of computing some result if the required
parameters are already available.
\end{itemize}

\begin{eqnarray*}
\matV & = & \ichol{K_M}\Kmn \\
\mat{Q_N} & = & \transm{V} \matV \\
\Lam & = & \diagm{\mat{K_N} - \mat{Q_N}} \\
\Lamss & = & \Lam + \sigma^2 \matI \\
\\
\uKmn & = & \Kmn \ichol{\Lamss} \\
\matB & = & \Km + \uKmn\uKnm \\
\\
\vecr & = & \diagv{\Lam} \\
\vecs & = & \diagv{\Lamss} \\
\vecis & = & \diagv{\Lamssi} \\
\\
l_1 & = & -\onehalf (\log|\matB| - \log|\Km| + \log|\Lamss| + N \log 2\pi) + \red{-\onehalf\vecis \cdot \vecr} \\
\\
\matR & = & \ichol{B}\Kmn \\
\matS & = & \icholt{B}\matR \Lamssi \\
\vect & = & \matS \vecy \\
\vece & = & \vecy - \Knm \vect \\
\vecu & = & \vecis \otimes \vece \\
\uuvecy & = & \Lamssi \vecy \\
\\
l_2 & = & \blue{-\onehalf \vecu\cdot\vecy} = -\onehalf(\uuvecy\cdot\vecy - \|\ichol{B}\Kmn\uuvecy\|^2) \\
l & = & l_1 + l_2 \\
\\
\matT & = & \imat{K_M} - \imat{B} \\
\\
\mu_* & = & \mat{K_{*M}} \vect \\
\sigma^2_* & = & K_* - \mat{K_{*M}}\matT\mat{K_{M*}} + \sigma^2 \matI \\
\end{eqnarray*}

\begin{eqnarray*}
\matU & = & \icholt{K_M}\mat{V} \\
\\
\vecvc & = & \vecs \red{\, + \, \vecs - \vecr} - \diagv{\transm{R}\matR} \\
\vecvx & = & \vecis \otimes (\vecis \otimes \vecvc) \\
\matUx & = & \matU \, \diagm{\vecvx^{\onehalf}} \\
\matWx & = & \matT - \matUx{\matU}_1^\top \\
\matXx & = & \matS - \matU\,\diagm{\vecvx} \\
\dl_1 & = & -\onehalf(\vecvx \cdot \diagv{\dKn} - \trace{\transm{W}_1\dKm}) - \trace{\transm{X}_1\dKmn} \\
\\
\vecvy & = & \vecu \otimes \vecu \\
\matUy & = & \matU \, \diagm{\vecu} \\
\matWy & = & \vect \vect^\top - \matUy\matUy^\top \\
\matXy & = & \vect\vecu^\top - \matU\,\diagm{\vecvy} \\
\dl_2 & = & \onehalf(\vecvy \cdot \diagv{\dKn} - \trace{\transm{W}_2\dKm}) + \trace{\transm{X}_2\dKmn} \\
\\
\dl & = & \dl_1 + \dl_2 \\
\\
\tfrac{\partial l_1}{\partial\sigma^2} & = & -\onehalf(\mathrm{sum}(\vecvx) \red{\, - \, \mathrm{sum}(\vecis)}) \\
\tfrac{\partial l_2}{\partial\sigma^2} & = & \onehalf\mathrm{sum}(\vecvy) \\
\tfrac{\partial l}{\partial\sigma^2} & = & \tfrac{\partial l_1}{\partial\sigma^2} + \tfrac{\partial l_2}{\partial\sigma^2}
\end{eqnarray*}
\blue{
\begin{eqnarray*}
\vecv & = & \vecvx - \vecvy = \vecis \otimes (\vecis \otimes (\vecvc - \vece \otimes \vece)) \\
\matW & = & \matWx - \matWy = \matT - \vect \transv{t} - \matUx{\matU}_1^\top + \matUy{\matU}_2^\top \\
\matX & = & \matXx - \matXy = \matS - \vect \transv{u} - \matU\,\diagm{\vecv} \\
\dl & = & -\onehalf(\vecv \cdot \diagv{\dKn} - \trace{\transm{W}\dKm}) - \trace{\transm{X}\dKmn} \\
\\
\tfrac{\partial l}{\partial\sigma^2} & = & -\onehalf(\mathrm{sum}(\vecv) \red{\, - \, \mathrm{sum}(\vecis)}) \\
\end{eqnarray*}
}

\section{Notes/reminders for future work}

Log-derivatives:

\begin{itemize}
\item $\tfrac{\partial f}{\partial \log(x)} = \tfrac{\partial f}{\partial x} x$
\end{itemize}

\subsection{Nonlinear clustering:}

\begin{itemize}
\item $k(x, y) = \langle \phi(x) | \phi(y) \rangle$
\item $\|\phi(x) - \phi(y)\|^2 = k(x,x)-2k(x,y)+k(y,y)$
\item find one inducing point
\item choose point x farthest away wrt.\ k
\item choose antipodal point y to x wrt.\ k
\item determine for all points to which of x or y they are closer
\item create two clusters
\item recurse
\item when suitable granularity reached, use PI(T)C
\end{itemize}

\end{document}
